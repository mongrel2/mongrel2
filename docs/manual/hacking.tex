\chapter{Hacking}

This chapter is all about making cool things with Mongrel2.  It covers all the non-deployment
features that you get from the browser's side and the handler/backend side of your application.
I'll show you how the chat demo works for the async web sockets.  I'll get into writing your
own handlers using a few other demos.  I'll cover some of the interesting things you can
do with Mongrel2 you can't do with other servers.  Finally, I'll get into practical things,
when to do proxying and when to use a 0MQ handler.

For the majority of this chapter, I'll be using Python, but the demos should translate to
the other languages that are implemented.  I'll periodically show how another language
does one of the demos, so you can get the idea that Mongrel2 is \emph{language agnostic}.
In no way should you take me using Python in this chapter to mean you can't use something
else for your handlers.

Currently supported languages are:

\begin{description}
\item [Python] When you installed the \shell{m2sh} gear, you also got a \ident{mongrel2} Python library.
\item [Ruby] Probably the most extensively supported language, with good Rack support, by \href{http://github.com/perplexes/m2r}{perplexes on github}.
\item [C++] C++ support by \href{http://github.com/akrennmair/mongrel2-cpp}{akrennmair on github}.
\item [PHP] PHP support by \href{http://github.com/winks/m2php}{winks on github}.
\item [C] You can also write handlers in C using the Mongrel2 library, but it's really rough, and not recommended yet.  A C library will come, though.
\item [Others?] \href{http://zeromq.org}{ZeroMQ} supports Ada, Basic, C, C++, Common Lisp, Erlang, Go, Haskell, Java, Lua, .NET, Objective-C, ooc, Perl, PHP, Python, and Ruby, so after reading this chapter you can easily write handlers in any of those languages too.
\end{description}

However, no matter how many languages Mongrel2 supports, you will still have applications that
can't fit into 0MQ handlers and just work better as classic web apps, either because you've
already written them and have existing infrastructure, or because of some architectural issues
that require it to run traditionally.  Because of that, Mongrel2 supports \emph{HTTP proxying},
which allows you to route requests to basic web server backends that don't support 0MQ.

\begin{aside}{What About FastCGI/AJP/CGI/SCGI/WSGI/Rack?}
Nothing prevents you from writing your own connector between Mongrel2 and your
deployment protocol of choice.  If you need to run FastCGI or AJP in your environment,
then your best bet is to just make a handler that translates Mongrel2 requests
to the protocol you need and back.  The Mongrel2 format is very easy to parse and
translate, so you should be able to do it with no problem.  The Ruby library already supports
Rack as an example, and Python will support WSGI soon.

However, Mongrel2 itself doesn't support any of these directly.  Doing so would bring
back the language specific infections that cause other web servers to go south.  The
design of most of these protocols tends to be either before the modern web, or specific
to one particular language.  Instead of trying to cater to all the possible languages
out there, Mongrel2 just gives the tools to connect to it yourself.
\end{aside}


\section{Front-end Goodies}

Mongrel2 supports your standard web server features like serving files, routing requests to
another HTTP server, multiple host matching, good 304 support, and just generally being able
to interact with a browser like normal.  You've seen most of these features as you setup and
deployed a Mongrel2 configuration, but let's go through some of them in more detail so you
know what's possible.


\subsection{HTTP}

Mongrel2 uses the original Mongrel parser that powers quite a few other web servers and large,
successful websites.  This parser is rock solid, dead accurate, and by design blocks a lot of
security attacks.  For the most part you don't have to worry about this and just need to know
Mongrel2 is using the same stable HTTP processing that has been working great for many years.

Another way to put this is if Mongrel2 says your request is invalid, it most definitely is.

\begin{aside}{Idiots and RFC Implementers}
I don't know why, but people who implement RFCs pick up very weird cargo cult
beliefs peddled by the people who write the standards.  In HTTP it was two things
which the creators of HTTP have actually pack-peddled on:  Accept everything, and
keep-alives with pipe-lines.

The truth is, if you want a secure server of \emph{any} kind, blindly accepting every
single thing any idiots sends you is going to open your server up to a huge number
of attacks.  If you look at every attack on existing HTTP servers you'll find that
about 80\% of them are exploiting ambiguous parts of the HTTP grammar to pass
through malicious content or overflow buffers.  In Mongrel2 we use a parser that rejects
invalid requests from first basic principles using technology that's 30 years old and
backed by solid mathematics.  Not only does Mongrel2 reject bad requests, but it can
tell you \emph{why} the request was bad, just like a compiler.  This doesn't mean
Mongrel2 is ruthless, but it definitely doesn't tolerate ambiguity or stupidity.

Mongrel2 completey supports keep-alives because now, since it's not using Ruby
\emph{at all} it can scale up beyond 1024 file descriptors.  Ruby was limited
in the number of open files a process could have, so the original Mongrel had
to break keep-alive and kill connections in order to save itself from greedy
browsers that never close them.  Mongrel2 doesn't have this limitation, so it
uses full keep-alives and has a dead accurate state machine to manage them correctly.

Where problems come in is with pipe-lined requests, meaning a browser sends a bunch
of requests in a big blast, then hangs out for all the responses.  This was such a
horrible stupid idea that pretty much everone gets it wrong and doesn't support it
fully, if at all.  The reason is it's much too easy to blast a server with a ton
of request, wait a bit so they hit proxied backends, and then close the socket.  The
web server and the backends are now screwed having to handle these requests which will
go nowhere.

Mongrel2 does \emph{not} support pipe-lined requests.  It sends one, and waits for the
reponse, and if you want more, then tough.  Screw you because it has \emph{no} advantage
for Mongrel2 and dubious advantages to you.  It is simply one more attack vector for
the server and is rejected outright.

These two things are rejected outright by Mongrel2 simply because they are stupid ideas
and in 2010 nobody should be writing clients so badly that they need these features.
\end{aside}

\subsection{Proxying}

You've already seen configurations that have the Proxy routes working, so it should
be easy to understand what's going on.  You just create routes to backends that are
HTTP servers and Mongrel2 shuttles requests to them, then proxies responses back.

The Proxying support in Mongrel2 is accurate, but it's not very capable right now.  For
example, there's not round-robin backend selection, or page caching, or other things you
might need for more serious deployments.  Those features will come eventually, though.

What you do get with Mongrel2's proxying, though, is a dead accurate way of slicing up
your application by routes.  Other web servers make you go through great pain in order
to have some URLs go to a proxy and others go to handlers or directories.  They make you
use odd "file syntax", weird pseudo-turing logic if-statements, and other odd hacks
to get flexible route selection.  They also tend to not maintain keep-alives properly
between proxy requests and other requests.

Mongrel2 uses the exact same routing syntax for all backends and has no distinction between
them.  It also properly does keep-alives for as long as it is efficient to do so.


\subsection{WebSockets}

Mongrel2 supports WebSockets, in that if someone connects with a WebSocket, then it will get
sent to handlers that use 0MQ and they can interact with it like every other request.  WebSockets
are the least supported, though, since they aren't fully baked and nobody's bothered to write
helper gear for handlers.  They work, in theory, but haven't really been tried in practice.

If you try them out and find things that need fixing, let us know.

\begin{aside}{Death To WebSockets}
I am getting sick of these "Backroom RFCs" that are crafted around a bunch of huge
companies' crap implementations found in their existing products rather than things
real programmers need.  WebSockets is yet another example of this, with so many odd
features and annoying agendas that I hope it fails miserably.

First, it actually specifies \emph{Unicode} for the wire protocol in the HTTP headers.
This is such a monumental bad idea and will break so many web servers and browsers that
I'm baffled how it got into the standard.  The only thing I can think of is some "reverse colonialist"
who thinks the world should a happy rainbow of Unicode demanded it be in there.  Unicode in
the wire protocol adds no linguistic value (nobody reads headers), complicates servers,
adds security concerns because Unicode is ambiguous, and also violates the existing HTTP standard
which specifies ASCII for the wire protocol.  As I've said before in this manual, writing
protocols is hard enough without having to translate and deal with weird UTF-8 Unicode bizarreness.

Second, there is an idiotic "encryption" mechanism for a key exchange that can only be
described as completely damaged and amateurish.  The scheme involves taking a regular
number and then mixing in non-number characters, so \verb|1234| becomes \verb|1@%^2*(34| and then is
"decrypted" by just reading only the digits.  Yes, this encryption is so advanced you can do it
in your head visually.  I'm sorry, but any obfuscation that can be done by an 11 year old on
paper is not encryption and should not be used at all.  Again, this smacks of some "clever" feature
one of the many corporations out there invented and not something any real programmer needs.

There's more, but these two alone are enough to decide to hold off on WebSockets until
they get their head straight and specify something that mere mortals can hope to implement.
\end{aside}

\subsection{JSSocket}

The Mongrel2 chat demo uses JSSocket to do its magic, and it works great, but it requires
Flash and, oh, man, do I absolutely hate Flash.  However, it works, and works now, and works in every
browser, even really old, busted ones.  That means it's the first thing we implemented and
the one we'll keep for a while until it proves itself not useful.  The chat demo we'll
cover will show you how to hook this up for fast async messaging and presence detection.


\subsection{Long Poll}

Mongrel2 just works as if everything is an HTTP long poll, it's just that normal request/responses
are super fast long polls.  For the most part you don't even need to know this exists; it's just
how things are and they make perfect sense.  You get requests from a certain server with a
certain connected identity, and then you send stuff to that target.  That's it.  If you send it
one response, or a stream of them, or setup a long poll configuration, then that's up to you.


\subsection{Streaming}

Because everything in Mongrel2 is asynchronous, and it allows you to target any connected listeners
from your handlers, even with partial messages, you can easily do efficient streaming applications.  ZeroMQ
is an incredibly efficient transport mechanism, and with it you can send tons of information to many
browsers or clients at once.  This means streaming video and MP3 streams to listeners is very
trivial.  We'll cover the mp3stream example where you get to see a simple implementation of the ICY
MP3 streaming protocol.

\subsection{N:M Responses}

What makes streaming, async messaging, and long poll designs so efficient in Mongrel2 is that you can send
\emph{one} message and target up to 128 clients with that one message.  This means sending large scale replies
to many browsers requires less copying of the message and less transports.

In addition to this, you can setup Mongrel2 with the help of some 0MQ to send
one request from a browser to as many target handlers as you like.  You can
even send them messages using \href{http://code.google.com/p/openpgm/}{OpenPGM}
for sending UDP messages reliably to clusters of computers.

This means that Mongrel2 is the only web server capable of sending one request
from a browser to N backends at once, and then return the replies from these
handlers to M browsers.  Not exactly sure what you could write with that, but
it's probably something really damn cool.


\section{Introduction to ZeroMQ}

Learning to use \href{http://zeromq.org}{ZeroMQ} is a bit outside the scope of this book, but I'll give you
a quick introduction to it so that you can explore it further.  It is a very simple
system, so hopefully you can figure it out from here.

What ZeroMQ ends up being is "sockets the way programmers think sockets work."  Programmers
usually hear about TCP or UDP sockets and they think in a naive way that they work like
this:

\begin{description}
\item [TCP] Programmers think these are streamed sequential messages, so if
   they send a "message" that's 10k long then when the receiver gets it and read
   from the TCP socket they get a single 10k message in reply.  This only works in
   small messages and not on the Internet, so it's easy to see how it would seem
   to work that way.  The reality is that you can get messages of any size, and without
   some framing mechanism you wouldn't know where one messages ends or beings.
   TCP is a \emph{streaming protocol}.

\item [UDP] Programmers think UDP sockets are single, fast, \emph{reliable} messages
    that can be sent to one or more target clients.  They at least know UDP has a fixed
    upper bound size, but they don't get that UDP is very unreliable and that the addressing
    is fairly weak.
\end{description}

What ZeroMQ does is create an API that looks a lot like sockets, and feels the
same, but gives you the messaging styles you actually want.  By simply
specifying the type of socket when you call
\href{http://api.zeromq.org/zmq\_socket.html}{zmq\_socket} you can have
multicast, request/reply, and many other styles.  Here's the list of ones
currently implemented (as documented in \shell{man zmq\_socket}):

\begin{description}
\item [ZMQ\_REQ ZMQ\_REP]  Your classic, strict, REQuest/REPly sockets, that work much like
    HTTP request/response semantics.  These are more strict and lock-step, but are slower
    because of the extra overhead in keeping the state organized.
\item [ZMQ\_PUB ZMQ\_SUB]  These are PUBlish/SUBscribe sockets and work as a decentralized
    asynchronous messaging.  PUB sockets just send out messages to multiple subscribers, without
    expecting a reply.  SUB sockets just read messages that are sent to them, and can subscribe
    to prefixes on the messages.
\item [ZMQ\_DOWNSTREAM ZMQ\_UPSTREAM] DOWN/UP sockets are more like asynchronous round-robin
    sockets.  They work like PUB/SUB, but instead of the message going to all subscribers that
    are subscribed or not, a DOWN/UP socket will have a message go to just one of the receivers
    in a cluster.  This is a lot like having a round-robin proxy configuration in your web server.
\item [ZMQ\_PAIR] A PAIR is just a direct connection between two peers, basically like a better
    TCP connection.
\end{description}

The next thing ZeroMQ does is it separates these types of \emph{messaging} from the underlying
transport protocol and gives you a simple URL-like syntax for specifying that: \shell{tcp://127.0.0.1:9999/}
for example.  The types of transports that you can use when you call \href{http://api.zeromq.org/zmq\_bind.html}{zmq\_bind}
and \href{http://api.zeromq.org/zmq\_connect.html}{zmq\_connect} are:

\begin{description}
\item [tcp://] This is a plain old TCP socket with a host and portnumber.
\item [ipc://] This uses Unix inter-process communication like domain sockets, mq, or whatever is available.
\item [pgm://] Reliable multicast messaging that uses raw IP layering and requires special privileges.
\item [epgm://] The "encapsulated" version that uses regular UDP to do reliable multicast messaging.
\end{description}

Finally, ZeroMQ divorces who binds and connects from the above two
configurations.  This means that, unlike classic sockets, who connects and who
binds doesn't matter for the direction or kind of message.  All that really
matters is whether the connection makes sense for your application.  For
example, in Mongrel2 the server does a bind on the handler ports so that
handlers can connect at will, which gives your handlers a nice "zero config"
setup.  Mongrel2 doesn't need to know about handlers; they just need to know
about Mongrel2.

How this last part works, and why it works, is that when clients or servers
connect or disconnect, ZeroMQ \emph{doesn't blow up}.  In TCP, if I have a
server, and then 10 clients connect, when one of them disconnects in the middle
of a message I lose the message and get an error.  With ZeroMQ, clients
connecting to a socket don't trigger an event, and disconnecting doesn't do
anything other than hold or drop messages.  This is why you don't have to care
about who binds or connects, because it's just an addressing mechanism, not a
\emph{state management} mechanism.

Another way to put this feature is there's no \emph{accept} in ZeroMQ.  Clients
connect and go at will and the server is just reading messages off when they're
available or sending them out for clients.


\subsection{A Quick Python ZeroMQ Example}

I've written a simple abstraction over ZeroMQ that fits the Mongrel2 usage of it, but
I think learning how you'd write your own ZeroMQ simple echo server in Python will
help you get a handle on it.  First the client then the server:

\begin{code}{Simple Python ZeroMQ Client}
\begin{Verbatim}
import zmq

ctx = zmq.Context()
s = ctx.socket(zmq.SUB)
s.connect("tcp://127.0.0.1:5566")
s.setsockopt(zmq.SUBSCRIBE, '')

msg = s.recv()
print "MSG: ", repr(msg)
\end{Verbatim}
\end{code}


\begin{code}{Simple Python ZeroMQ Server}
\begin{Verbatim}
import zmq
import time

ctx = zmq.Context()
s = ctx.socket(zmq.PUB)
s.bind("tcp://127.0.0.1:5566")

while True:
    s.send("HELLO")
    time.sleep(1)
\end{Verbatim}
\end{code}


You can then run these two in different windows and they will talk to each
other.  Try playing around with different socket types and transports to see
what they do.  Notice that for a PUB/SUB setup we have to use \ident{setsockopt}
to subscribe the nothing ('').  This is the same no matter what language you
use.

Here's an example that does the same thing but with REQ/REP style of messages.

\begin{code}{ZeroMQ REQ/REP Client}
\begin{Verbatim}
import zmq

ctx = zmq.Context()
s = ctx.socket(zmq.REQ)
s.connect("tcp://127.0.0.1:5566")

s.send('HI FROM CLIENT')

msg = s.recv()
print "MSG: ", repr(msg)
\end{Verbatim}
\end{code}


\begin{code}{ZeroMQ REQ/REP Server}
\begin{Verbatim}
import zmq

ctx = zmq.Context()
s = ctx.socket(zmq.REP)
s.bind("tcp://127.0.0.1:5566")

while True:
    print "GOT BACK", repr(s.recv())
    s.send("HELLO")
\end{Verbatim}
\end{code}

As you can see when you run this, it's more like your classic web server style of messaging,
where a client requests something with an initial message, and the server replies.  Try getting
the order wrong and see how ZeroMQ aborts and tells you it's wrong.  REQ sockets \emph{must} send
first then recv, and REP sockets \emph{must} recv then send.

\begin{aside}{There's Always a Size in ZeroMQ Land}
The lack of a reliable framing mechanism in TCP was a crime against humanity.  What I mean by a
"frame" is a simple indicator that a message in a stream has a certain length.  If you preface
each message in TCP with the length of the data you're about to send then you avoid all manner
of annoyance, attacks, and bugs.  Something as simple as a single byte that says you're sending up
to 128 more bytes, with an extra bit to indicate the last byte would have saved the world much
pain.

This is basically what ZeroMQ has done, and so much more.  ZeroMQ pulls out all the tricks to make
sure that the message you receive is totally cooked, fully sized, and transports it faster than
TCP can actually send it.  It does this by framing things intelligently, using compression, reducing
copying, and just generally being awesome.

Of course, the only limitation is that it can't really \emph{stream} things. But then again, nobody
really does true streaming.  They always end up having to bolt on some framing of some kind.
\end{aside}


\section{Handler ZeroMQ Format}

You've had the world's fastest crash course in \href{http://zeromq.org}{ZeroMQ} and now you're
ready to see how Mongrel2 talks to your handlers with it.  I won't really call this a "protocol",
since ZeroMQ is really doing the protocol, and we just pull fully baked messages out of it.  Instead,
this is just a format, as if you got strings out of a file or something similar.  This message
format is designed to accomplish a few things in the simplest way possible:

\begin{enumerate}
\item Be usable from languages that are statically compiled or scripting languages.
\item Be safe from buffer overflows if done right, or easy to do right.
\item Be easy to understand and require very little code.
\item Be language agnostic and use a data format everyone can accept without complaining
    that it should be done with their favorite\footnote{Except Erlang guys, 'cause they'll always
    complain that everything's not in Erlang}.
\item Be easy to parse and generate inside Mongrel2 \emph{without} have to parse the entire message
    to do routing or analysis.
\item Be useful within ZeroMQ so that you can do subscriptions and routing.
\end{enumerate}

To satisfy these features we use haveo types of ZeroMQ sockets (soon to be configurable),
a request format that Mongrel2 sends and a response format that the handlers send back.  Most
importantly, there is \emph{nothing about the request and response that must be connected}.  In most
cases they will be connected, but you can receive a request from one browser and send a response
to a totally different one.

\subsection{Socket Types Used}

First, the types of ZeroMQ sockets used are a \ident{ZMQ\_DOWNSTREAM} socket
for messages from Mongrel2 to Handlers, which means your Handler's receive
socket should be a \ident{ZMQ\_UPSTREAM}.  Mongrel2 then uses a
\ident{ZMQ\_SUB} socket for receiving responses, which means your Handlers
should send on a \ident{ZMQ\_PUB} socket.  This setup
allows multiple handlers to connect to a Mongrel2 server, but only
one Handler will get a message in a round-robin style.  The PUB/SUB reply
sockets, though, will let Handlers send back replies to a cluster of
Mongrel2 servers, but only the one with the right subscription will
process the request.\footnote{The types of sockets used will be configurable
in later version}

In the various APIs we've implemented, you don't need to care about this.
They provide an abstraction on top of this, but it does help to know it
so that you understand why the message format is the way it is.

This leads to rule number 1:

\begin{quote}
\emph{Rule 1:} Handlers receive on with UPSTREAM and send with PUB sockets.
\end{quote}

\subsection{UUID Addressing}

Do you remember all those UUIDs all over the place in the configuration files?
They may have seemed odd, but they identify specific server deployments and
processes in a cluster.  This will let you identify exactly which member of a
cluster sent a message, so that you can return the right reply.  This is the
first part of our protocol format and it results in the next rule 2:

\begin{quote}
\emph{Rule 2:} Every message to and from Mongrel2 has that Mongrel2 instance's
UUID as the very first thing.
\end{quote}

\subsection{Numbers Identify Listeners}

You then need a way to identify a particular listener (browser, client, etc.)
that your message should target, \emph{and} Mongrel2 needs to tell you who is
sending your handler the request.  This means Mongrel2 sends you is just one
identifier, but you can send Mongrel2 a list of them.  This leads to rule 3:

\begin{quote}
\emph{Rule 3:} Mongrel2 sends requests with one number right after the server's
UUID separated by a space.  Handlers return a \emph{netstring} with a list of
numbers separated by spaces.  The numbers indicate the connected browser the
message is to/from.
\end{quote}

In case you don't know what a netstring is, it is a very simple way to encode a
block of data such that any language can read the block and know how big it is.
A netstring is, simply, \verb|SIZE:DATA,|. So, to send "HI", you would do
\verb|2:HI,|, and it is \emph{incredibly} easy to parse in every language, even
C.  It is also a fast format and you can read it even if you're a human.


\subsection{Paths Identify Targets}

In order to make it possible to route or analyze a request in your handlers
without having to parse a full request, every request has the path that
was matched in the server as the next piece.  That gives us:

\begin{quote}
\emph{Rule 4:} Requests have the path as a single string followed by a
    space and \emph{no paths may have spaces in them}.
\end{quote}


\subsection{Request Headers And Body}

We only have two more rules to complete the message format.

\begin{quote}
\emph{Rule 5:} Mongrel2 sends requests with a \ident{netstring} that contains a
JSON hash (dict) of the request headers, and then another \ident{netstring}
with the body of the request.
\end{quote}

Then there's a similar rule for responses:

\begin{quote}
\emph{Rule 6:} Handlers return just the body after a space character.  It can be \emph{any}
    data that Mongel2 is supposed to send to the listeners.
\end{quote}

HTTP headers, image data, HTML pages, streaming video\ldots You can also send as
many as you like to complete the request and any handler can send it.


\subsection{Complete Message Examples}

Now, even though we laid out all of this as a series of rules, the actual code to implement
these is very simple.  First here's a simple "grammar" for how a request that
gets sent to your handlers is formatted:

\begin{Verbatim}
UUID ID PATH SIZE:HEADERS,SIZE:BODY,
\end{Verbatim}

That's obviously a much simpler way to specify the request than all those
rules, but it also doesn't tell you why.  The above description, while
boring as hell, tells you why each of these pieces exist.

To parse this in Python we simply do this:

\begin{code}{Parsing Mongrel2 Requests In Python}
\begin{Verbatim}
import json

def parse_netstring(ns):
    len, rest = ns.split(':', 1)
    len = int(len)
    assert rest[len] == ',', "Netstring did not end in ','"
    return rest[:len], rest[len+1:]

def parse(msg):
    sender, conn_id, path, rest = msg.split(' ', 3)
    headers, rest = parse_netstring(rest)
    body, _ = parse_netstring(rest)

    headers = json.loads(headers)

    return uuid, id, path, headers, body
\end{Verbatim}
\end{code}

This is actually all of the code needed to parse a request, and is
fairly the same in many other languages.  If you look at the file
\file{examples/python/mongrel2/request.py}, you'll see a more complete
example of making a full request object.

A response is then just as simple and involves crafting a similar
setup like this:

\begin{Verbatim}
UUID SIZE:ID ID ID, BODY
\end{Verbatim}

Notice I've got three IDs here, but you can do anywhere from 1 up to 128.  Generating
this is very easy in Python:

\begin{code}{Generating Responses}
\begin{Verbatim}

def send(uuid, conn_id, msg):
    header = "%s %d:%s," % (uuid, len(str(conn_id)), str(conn_id))
    self.resp.send(header + ' ' + msg)


def deliver(uuid, idents, data):
    self.send(uuid, ' '.join(idents), data)

\end{Verbatim}
\end{code}

That, again, is all there is to it.  The \ident{send} method is the
one doing the real work of crafting the response, and the \ident{deliver}
method is just using \ident{send} to do all the the target idents
joined with a space.


\subsection{Python Handler API}

Instead of building all of this yourself, I've created a Python library
that wraps all this up and makes it easy to use.  Each of the other
libraries are designed around the same idea and should have a similar
design.  To check out how to use the Python API, we'll take a look at
each of the demos that are available.  These are the same demos you
ran in the previous section to create a sample deployment.

To look at the Python API, take a look at
\file{examples/python/mongrel2/request.py} and
\file{examples/python/mongrel2/handler.py}.  They are very small files that you
should be able to understand quickly.


\section{Basic Handler Demo}

The most basic handler you can write is in the \file{examples/http\_0mq/http.py} file
and it just the simplest thing possible:\footnote{This is the same code as the original
file, but with extraneous prints removed for simplicity.}

\begin{code}{http.py example}
\begin{Verbatim}
from mongrel2 import handler
import json

sender_id = "82209006-86FF-4982-B5EA-D1E29E55D481"

conn = handler.Connection(sender_id, "tcp://127.0.0.1:9997",
                          "tcp://127.0.0.1:9996")
while True:
    print "WAITING FOR REQUEST"

    req = conn.recv()

    if req.is_disconnect():
        continue

    response = "<pre>\nSENDER: %r\nIDENT:%r\nPATH: %r\nHEADERS:%r\nBODY:%r</pre>" % (
        req.sender, req.conn_id, req.path,
        json.dumps(req.headers), req.body)

    conn.reply_http(req, response)
\end{Verbatim}
\end{code}

All this code does is print back a simple little dump of what it received, and
it's not even a valid HTML document.  Let's walk through everything that's going on:

\begin{enumerate}
\item Import the \ident{handler} module from \ident{mongrel2} and \ident{json}.  The \ident{json} module is
    really only used for logging.
\item Establish the UUID for our handler, and create a connection.  It's not \emph{really} a connection
    but more of a "virtual circuit" that you can just pretend is a connection.  It's using all ZeroMQ and
    the protocol we just described to create a simple API to use.
\item Go into a while loop forever and recv request objects off the connection.
\item One type of special message we can get from Mongrel2 is a "disconnect" message, which tells you that
    one of the listeners you tried to talk to was closed.  You should either ignore those and read
    another, or update any internal state you may have.  They can come asynchronously, and for the most
    part you can ignore them unless you need to keep them open as in, say, a chat application or streaming.
\item Craft the reply you're going to send back, which is just a dump of what you received.
\item Send this reply back to Mongrel2.  Notice the subtle difference where you include the \emph{req} object
    as part of how you reply?  This is the major difference between this API and more traditional
    request/response APIs in that you need the request you are responding to so that it knows where to send
    things.  In a normal socket-based server this is just assumed to be the socket you're talking about.
\end{enumerate}

This is all you need at first to do simple HTTP handlers.  In reality, the \ident{reply\_http} method is
just syntactic sugar on crafting a decent HTTP response.  Here's the actual method that is crafting these replies:

\begin{code}{HTTP Response Python Code}
\begin{Verbatim}
def http_response(body, code, status, headers):
    payload = {'code': code, 'status': status, 'body': body}
    headers['Content-Length'] = len(body)
    payload['headers'] = "\r\n".join('%s: %s' % (k,v) for k,v in
                                     headers.items())

    return HTTP_FORMAT % payload

\end{Verbatim}
\end{code}

Which is then used by \ident{Connection.reply\_http} and
\ident{Connection.deliver\_http} to send an actual HTTP response.  That
means all this is doing is creating the raw bytes you want to go
to the real browser, and how it's delivered is irrelevant.  For example,
the \ident{deliver\_http} method means that, yes, you can have one
handler send a single response to target \emph{multiple} browsers
at once.


\section{MP3 Streaming Demo}

The next example is a very simple and, well, kind of poorly implemented
MP3 streaming demo that uses the ICY protocol.  ICY is a really lame
protocol that was obviously designed before HTTP was totally baked
and probably by people who don't really get HTTP.  It works in an odd
way of having meta-data sent at specific sized intervals so the
client can display an update to the meta-data.

The mp3streamer demo creates a streaming system by
having a thread that receives requests for connections, and then
another thread that sends the current data to all currently connected
clients.  Rather than go through all the code, you can take a look
at the main file and see how simple it is once you get the
streaming thread right:

\begin{code}{Base mp3stream Code}
\begin{Verbatim}
from mp3stream import ConnectState, Streamer
from mongrel2 import handler
import glob


sender_id = "9703b4dd-227a-45c4-b7a1-ef62d97962b2"

CONN = handler.Connection(sender_id, "tcp://127.0.0.1:9995",
                          "tcp://127.0.0.1:9994")

MP3_FILES = glob.glob("*.mp3")

print "PLAYING:", MP3_FILES

CHUNK_SIZE = 5 * 1024

STATE = ConnectState()

STREAMER = Streamer(MP3_FILES, STATE, CONN, CHUNK_SIZE)
STREAMER.start()


while True:
    req = CONN.recv()

    if req.is_disconnect():
        print "DISCONNECT", req.headers, req.body, req.conn_id
        STATE.remove(req)
    else:
        print "REQUEST", req.headers, req.body

        if STATE.count() > 20:
            print "TOO MANY", STATE.count()
            CONN.reply_http(req, "Too Many Connected.  Try Later.")
        else:
            STATE.add(req)
            CONN.reply_http(req, "", headers={'icy-metaint': CHUNK_SIZE})
\end{Verbatim}
\end{code}

Walking through this example is fairly easy, assuming you just trust
that the streaming thread stuff works:

\begin{enumerate}
\item Starts off just like the handler test.
\item We figure out what .mp3 files are in the current directory.
\item Establish a data chunk size of 5k for the ICY protocol and
    make a ConnectState and Streamer from that.  These are the
    streaming thread things found in \file{mp3stream.py} in the same
    directory.
\item We then loop forever, accepting requests.
\item Unlike the handler, we want to remove disconnected clients,
    so we take them out of the STATE when we are notified.
\item If we have too many connected clients, we reply with a failure.
\item Otherwise, we add them to the STATE and then send the initial
    ICY protocol header to get things going.
\end{enumerate}


That is the base of it, and if you point mplayer at it (which is
the only player that works, really) you should hear it play:

\begin{Verbatim}
> mplayer http://localhost:6767/mp3stream
\end{Verbatim}

That is, assuming you put some mp3 files into the directory and
started the handler again.

For more on how the actual state and the protocol works, go look
at mp3stream.py.  Explaining it is far outside the scope of this manual,
but the key points to realize are that this is one thread that's
targetting randomly connected clients with a single message to the
Mongrel2 server and streaming it.


\section{Chat Demo}

The chat demo is the most involved demonstration, and I'm kind of getting
tired of leading you by the hand, so you go read the code.  Here's where
to look:

\begin{description}
\item [JavaScript] Look at \file{examples/chat/static/*.js} for the goodies.
    The key is to see how \file{chat.js} works with the JSSocket stuff,
    and then look at how I did \file{app.js} using \file{fsm.js}.
\item [Python] Look at the \file{examples/chat/chat.py} file to see how
    the chat states are maintained and how messages are sent around.
\item [config] The configuration you created in the last chapter
    actually works with the demo, and if you've been following along
    you should have tested it.
\end{description}

Hopefully, you can figure it out from the code, but if not, let me know.


\section{Other Language APIs}

As mentioned before, there are currently APIs for Ruby, C++, and PHP in
addition to the Python code:


\begin{description}
\item [Python] When you installed the \shell{m2sh} gear, you also got a \ident{mongrel2} Python library.
\item [Ruby] Probably the most extensively supported language, with good Rack support, by \href{http://github.com/perplexes/m2r}{perplexes on github}.
\item [C++] C++ support by \href{http://github.com/akrennmair/mongrel2-cpp}{akrennmair on github}.
\item [PHP] PHP support by \href{http://github.com/winks/m2php}{winks on github}.
\end{description}


If you want to implement another language, it should be fairly trivial.
Just base your design on the Python API so that it is consistent, but, please,
don't be a slave to the Python design if it doesn't fit the chosen language;
creating a direct translation of the Python is fine at first, but try
to make it idiomatic after that so people who use that language feel at
home and it's easy for them.


\section{Writing Your Own m2sh}

The very last thing I will cover in the section on hacking Mongrel2 is how to
write your own \shell{m2sh} script in your favorite language.  Obviously, if
you're doing this you should probably have a good reason\footnote{Like if
you're a Ruby weenie and Python is banned at your company because they like
dogma more than money.}.  What writing your own, or understanding what
\shell{m2sh} is doing will do for you, though, is help you when you start to
think about automating Mongrel2 for your deployments.

Hopefully, I may have motivated you to automate, automate, automate.
This is why we write software.  If I wanted to do stuff manually I'd
go play guitars or juggle.  I write software because I want a computer
to do things for me, and nothing needs this more than managing your systems.

This is why Mongrel2 is designed the way it is, using the MVC model.  It
lets \emph{you} create your own View like m2sh, web interfaces, automation
scripts, and anything else you need to make it easier to manage more.

If you want to write your own \shell{m2sh} then first go have a look at
the Python code in \file{examples/python/config}.  This is where each
command lives, where the argument parsing is and, most importantly, the
ORM model that works the raw SQLite database.

The next thing to do is to make your tool craft databases and compare the
results to what m2sh does for a similar configuration.  I recommend you make
a database that's "correct" with m2sh, and then dump it via \shell{sqlite3}.
After that, use your tool to make your own database, dump it, and then use
\shell{diff} to compare your results to mine.

Finally, the base schema files you'll need to look at are in
\file{src/config/config.sql} and \file{src/config/mimetypes.sql}, where
the database schema is created and the large list of mimetypes that
Mongrel2 knows is stored.\footnote{Incidentally, if you want to add one,
that's the table to put it in.}  Your tool should be able to use this
SQL to make its database, or at least know what it does.

If you do something cool with all of this, let us know.
